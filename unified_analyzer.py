"""
ÌÜµÌï© ABAP Î∂ÑÏÑù ÏóîÏßÑ
Ìå®ÌÑ¥ Îß§Ïπ≠Í≥º Ïò§Ïóº Ï∂îÏ†ÅÏùÑ Í≤∞Ìï©Ìïú Ï¢ÖÌï© Î∂ÑÏÑù ÏãúÏä§ÌÖú
"""

import re
import json
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass, asdict
from datetime import datetime
from improved_patterns import ImprovedPatternMatcher, OperationType


@dataclass
class AnalysisContext:
    """Î∂ÑÏÑù Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥"""
    current_form: Optional[str] = None
    current_loop_depth: int = 0
    current_rfc: Optional[str] = None
    scope_stack: List[str] = None
    
    def __post_init__(self):
        if self.scope_stack is None:
            self.scope_stack = []


class UnifiedAnalyzer:
    """ÌÜµÌï© ABAP Î∂ÑÏÑùÍ∏∞"""
    
    def __init__(self, seed_variables: List[str] = None):
        self.seed_variables = seed_variables or ['SY-UNAME']
        self.pattern_matcher = ImprovedPatternMatcher()
        self.context = AnalysisContext()
        
        # Ï∂îÏ†Å ÏÉÅÌÉú
        self.propagation_graph: Dict[str, Set[str]] = {}
        self.variable_scopes: Dict[str, str] = {}
        self.trace_steps: List[str] = []
        
        # Î∂ÑÏÑù Í≤∞Í≥º
        self.analysis_result = {
            'source': ', '.join(self.seed_variables),
            'tainted_variables': [],
            'data_flows': [],
            'database_sinks': [],
            'propagation_paths': [],
            'trace_steps': [],
            'statistics': {}
        }
    
    def analyze(self, code_snippet: List[str], start_line: int = 0) -> Dict:
        """
        ÏΩîÎìú Ïä§ÎãàÌé´ Î∂ÑÏÑù
        
        Args:
            code_snippet: Î∂ÑÏÑùÌï† ÏΩîÎìú ÎùºÏù∏ Î¶¨Ïä§Ìä∏
            start_line: ÏãúÏûë ÎùºÏù∏ Î≤àÌò∏ (0-based)
        
        Returns:
            Î∂ÑÏÑù Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
        """
        start_time = datetime.now()
        
        # Ï¥àÍ∏∞Ìôî
        self._reset_state()
        
        # SY-UNAME ÏúÑÏπò ÌôïÏù∏
        if not self._verify_seed_location(code_snippet, start_line):
            return self._create_error_result("SY-UNAME not found at specified line")
        
        # Phase 1: Íµ¨Ï°∞ Î∂ÑÏÑù
        self._analyze_structure(code_snippet)
        
        # Phase 2: Ìå®ÌÑ¥ Í∏∞Î∞ò Î∂ÑÏÑù
        self._perform_pattern_analysis(code_snippet, start_line)
        
        # Phase 3: Ï†ÑÌåå Í≤ΩÎ°ú Ïû¨Íµ¨ÏÑ±
        self._reconstruct_propagation_paths()
        
        # Phase 4: Ïã†Î¢∞ÎèÑ ÌèâÍ∞Ä
        self._apply_confidence_scoring()
        
        # ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
        execution_time = (datetime.now() - start_time).total_seconds()
        self._add_statistics(len(code_snippet), execution_time)
        
        return self.analysis_result
    
    def _reset_state(self):
        """ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî"""
        self.pattern_matcher = ImprovedPatternMatcher()
        self.context = AnalysisContext()
        self.propagation_graph.clear()
        self.variable_scopes.clear()
        self.trace_steps.clear()
    
    def _verify_seed_location(self, code_snippet: List[str], start_line: int) -> bool:
        """ÏãúÎìú Î≥ÄÏàò ÏúÑÏπò ÌôïÏù∏"""
        if start_line >= len(code_snippet):
            self.trace_steps.append(f"‚ùå Line {start_line + 1} out of range")
            return False
        
        target_line = code_snippet[start_line].strip()
        
        # Ï£ºÏÑùÏù¥ÎÇò Îπà Ï§Ñ ÌôïÏù∏
        if not target_line or target_line.startswith('*'):
            self.trace_steps.append(f"‚ùå Line {start_line + 1} is empty or comment")
            return False
        
        # SY-UNAME Ï°¥Ïû¨ ÌôïÏù∏
        for seed in self.seed_variables:
            if seed.upper() in target_line.upper():
                self.trace_steps.append(f"‚úÖ {seed} found at line {start_line + 1}")
                # ÏãúÎìú Î≥ÄÏàòÎ•º Ïò§ÏóºÎêú Í≤ÉÏúºÎ°ú Ï¥àÍ∏∞ ÌëúÏãú
                self.pattern_matcher._mark_tainted(seed, start_line + 1, "Seed variable")
                return True
        
        self.trace_steps.append(f"‚ùå No seed variables found at line {start_line + 1}")
        return False
    
    def _analyze_structure(self, code_snippet: List[str]):
        """ÏΩîÎìú Íµ¨Ï°∞ Î∂ÑÏÑù"""
        for i, line in enumerate(code_snippet):
            line = line.strip()
            if not line or line.startswith('*'):
                continue
            
            # FORM Ï†ïÏùò Ï∂îÏ†Å
            form_match = re.match(r'^\s*FORM\s+(\w+)', line, re.IGNORECASE)
            if form_match:
                form_name = form_match.group(1).upper()
                self.context.current_form = form_name
                self.context.scope_stack.append(f"FORM:{form_name}")
                self.trace_steps.append(f"üìç Entering FORM {form_name} at line {i + 1}")
            
            # ENDFORM Ï∂îÏ†Å
            if re.match(r'^\s*ENDFORM', line, re.IGNORECASE):
                if self.context.scope_stack and self.context.scope_stack[-1].startswith('FORM:'):
                    leaving_form = self.context.scope_stack.pop()
                    self.trace_steps.append(f"üìç Leaving {leaving_form} at line {i + 1}")
                self.context.current_form = None
            
            # LOOP Ï∂îÏ†Å
            if re.match(r'^\s*LOOP', line, re.IGNORECASE):
                self.context.current_loop_depth += 1
                self.context.scope_stack.append(f"LOOP:{i + 1}")
                self.trace_steps.append(f"üîÑ Entering LOOP at line {i + 1}")
            
            # ENDLOOP Ï∂îÏ†Å
            if re.match(r'^\s*ENDLOOP', line, re.IGNORECASE):
                if self.context.current_loop_depth > 0:
                    self.context.current_loop_depth -= 1
                    if self.context.scope_stack and self.context.scope_stack[-1].startswith('LOOP:'):
                        leaving_loop = self.context.scope_stack.pop()
                        self.trace_steps.append(f"üîÑ Leaving {leaving_loop} at line {i + 1}")
            
            # RFC Ìò∏Ï∂ú Ï∂îÏ†Å
            rfc_match = re.match(r"^\s*CALL\s+FUNCTION\s+'([^']+)'", line, re.IGNORECASE)
            if rfc_match:
                self.context.current_rfc = rfc_match.group(1)
                self.trace_steps.append(f"üìû RFC call to {self.context.current_rfc} at line {i + 1}")
    
    def _perform_pattern_analysis(self, code_snippet: List[str], start_line: int):
        """Ìå®ÌÑ¥ Í∏∞Î∞ò Î∂ÑÏÑù ÏàòÌñâ"""
        # ÏãúÏûë ÎùºÏù∏Î∂ÄÌÑ∞ Î∂ÑÏÑù
        for i in range(start_line, len(code_snippet)):
            line = code_snippet[i].strip()
            if not line or line.startswith('*'):
                continue
            
            # Ìå®ÌÑ¥ Îß§Ï≤òÎ°ú ÎùºÏù∏ Î∂ÑÏÑù
            self.pattern_matcher.analyze_line(line, i + 1)
            
            # ÌòÑÏû¨ Ïä§ÏΩîÌîÑ Ï†ÄÏû•
            current_scope = self._get_current_scope()
            for var_name in self.pattern_matcher.tainted_variables:
                if var_name not in self.variable_scopes:
                    self.variable_scopes[var_name] = current_scope
            
            # Ï§ëÏöîÌïú ÏûëÏóÖ Î°úÍπÖ
            self._log_important_operations(line, i + 1)
    
    def _log_important_operations(self, line: str, line_number: int):
        """Ï§ëÏöîÌïú ÏûëÏóÖ Î°úÍπÖ"""
        line_upper = line.upper()
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏûëÏóÖ
        if any(op in line_upper for op in ['INSERT', 'UPDATE', 'MODIFY', 'DELETE']):
            for sink in self.pattern_matcher.database_sinks:
                if sink.line == line_number:
                    fields_str = ', '.join(sink.fields) if sink.fields else 'ALL'
                    self.trace_steps.append(
                        f"üíæ {sink.operation} {sink.table} at line {line_number} (Fields: {fields_str})"
                    )
        
        # Ìï†Îãπ ÏûëÏóÖ
        for flow in self.pattern_matcher.data_flows:
            if flow.line == line_number and flow.operation == OperationType.ASSIGNMENT:
                self.trace_steps.append(
                    f"‚û°Ô∏è Assignment: {flow.source} ‚Üí {flow.target} at line {line_number}"
                )
    
    def _reconstruct_propagation_paths(self):
        """Ï†ÑÌåå Í≤ΩÎ°ú Ïû¨Íµ¨ÏÑ±"""
        # Ï†ÑÌåå Í∑∏ÎûòÌîÑ Íµ¨Ï∂ï
        for flow in self.pattern_matcher.data_flows:
            if flow.source not in self.propagation_graph:
                self.propagation_graph[flow.source] = set()
            self.propagation_graph[flow.source].add(flow.target)
        
        # ÏãúÎìú Î≥ÄÏàòÎ∂ÄÌÑ∞ sinkÍπåÏßÄ Í≤ΩÎ°ú Ï∂îÏ†Å
        paths = []
        for seed in self.seed_variables:
            seed_upper = seed.upper()
            visited = set()
            current_path = []
            self._trace_path(seed_upper, visited, current_path, paths)
        
        self.analysis_result['propagation_paths'] = paths
    
    def _trace_path(self, current: str, visited: Set[str], current_path: List[str], all_paths: List):
        """DFSÎ•º ÏÇ¨Ïö©Ìïú Í≤ΩÎ°ú Ï∂îÏ†Å"""
        if current in visited:
            return
        
        visited.add(current)
        current_path.append(current)
        
        # ÌòÑÏû¨ Î≥ÄÏàòÍ∞Ä sinkÏóê ÎèÑÎã¨ÌïòÎäîÏßÄ ÌôïÏù∏
        for sink in self.pattern_matcher.database_sinks:
            if sink.source_variable == current or current in [f"{sink.table}-{f}" for f in sink.fields]:
                all_paths.append({
                    'variable': current,
                    'path': ' ‚Üí '.join(current_path),
                    'sink': f"{sink.operation} {sink.table}"
                })
        
        # Îã§Ïùå ÎÖ∏Îìú ÌÉêÏÉâ
        if current in self.propagation_graph:
            for next_var in self.propagation_graph[current]:
                self._trace_path(next_var, visited, current_path, all_paths)
        
        current_path.pop()
        visited.remove(current)
    
    def _apply_confidence_scoring(self):
        """Ïã†Î¢∞ÎèÑ Ï†êÏàò Ï†ÅÏö©"""
        # Îç∞Ïù¥ÌÑ∞ ÌùêÎ¶Ñ Ïã†Î¢∞ÎèÑ
        for flow in self.pattern_matcher.data_flows:
            confidence = 0.5  # Í∏∞Î≥∏ Ïã†Î¢∞ÎèÑ
            
            # ÏûëÏóÖ Ïú†ÌòïÎ≥Ñ Ïã†Î¢∞ÎèÑ
            if flow.operation in [OperationType.ASSIGNMENT, OperationType.STRUCTURE_FIELD]:
                confidence = 0.9
            elif flow.operation in [OperationType.DATABASE_INSERT, OperationType.DATABASE_UPDATE]:
                confidence = 0.95
            elif flow.operation in [OperationType.RFC_CALL, OperationType.PERFORM_CALL]:
                confidence = 0.6
            
            # Ïä§ÏΩîÌîÑ Í∏∞Î∞ò Ï°∞Ï†ï
            if flow.target in self.variable_scopes:
                scope = self.variable_scopes[flow.target]
                if scope.startswith('LOOP:'):
                    confidence *= 0.9  # Î£®ÌîÑ ÎÇ¥Î∂ÄÎäî ÏïΩÍ∞Ñ ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ
            
            flow.confidence = confidence
        
        # Sink Ïã†Î¢∞ÎèÑ
        for sink in self.pattern_matcher.database_sinks:
            confidence = 0.7  # Í∏∞Î≥∏ Ïã†Î¢∞ÎèÑ
            
            # ÏßÅÏ†ë DB ÏûëÏóÖÏùÄ ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ
            if not sink.operation.startswith('INDIRECT_'):
                confidence = 0.9
            
            # ÌïÑÎìúÍ∞Ä Î™ÖÏãúÎêú Í≤ΩÏö∞ Îçî ÎÜíÏùÄ Ïã†Î¢∞ÎèÑ
            if sink.fields:
                confidence = min(0.95, confidence + 0.1 * len(sink.fields))
            
            # Z/Y ÌÖåÏù¥Î∏îÏùÄ ÏµúÍ≥† Ïã†Î¢∞ÎèÑ
            if sink.table.startswith(('Z', 'Y')):
                confidence = min(0.99, confidence + 0.1)
            
            sink.confidence = confidence
    
    def _get_current_scope(self) -> str:
        """ÌòÑÏû¨ Ïä§ÏΩîÌîÑ Î∞òÌôò"""
        if not self.context.scope_stack:
            return 'GLOBAL'
        return self.context.scope_stack[-1]
    
    def _add_statistics(self, total_lines: int, execution_time: float):
        """ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï∂îÍ∞Ä"""
        pattern_result = self.pattern_matcher.get_analysis_result()
        
        self.analysis_result.update({
            'tainted_variables': pattern_result['tainted_variables'],
            'data_flows': pattern_result['data_flows'],
            'database_sinks': pattern_result['database_sinks'],
            'trace_steps': self.trace_steps[:10],  # Ï≤òÏùå 10Í∞úÎßå
            'statistics': {
                'total_lines': total_lines,
                'tainted_count': len(pattern_result['tainted_variables']),
                'flow_count': len(pattern_result['data_flows']),
                'sink_count': len(pattern_result['database_sinks']),
                'execution_time': f"{execution_time:.3f}s"
            }
        })
    
    def _create_error_result(self, reason: str) -> Dict:
        """Ïò§Î•ò Í≤∞Í≥º ÏÉùÏÑ±"""
        return {
            'status': 'Not Found',
            'reason': reason,
            'trace_steps': self.trace_steps,
            'statistics': {
                'total_lines': 0,
                'tainted_count': 0,
                'flow_count': 0,
                'sink_count': 0
            }
        }
    
    def export_report(self, output_file: str = None) -> str:
        """Î∂ÑÏÑù Î≥¥Í≥†ÏÑú ÏÉùÏÑ±"""
        report = []
        report.append("=" * 80)
        report.append("ABAP TAINT ANALYSIS REPORT")
        report.append("=" * 80)
        report.append(f"Timestamp: {datetime.now().isoformat()}")
        report.append(f"Source Variables: {self.analysis_result['source']}")
        report.append("")
        
        # ÏöîÏïΩ
        stats = self.analysis_result.get('statistics', {})
        report.append("SUMMARY")
        report.append("-" * 40)
        report.append(f"Tainted Variables: {stats.get('tainted_count', 0)}")
        report.append(f"Data Flows: {stats.get('flow_count', 0)}")
        report.append(f"Database Sinks: {stats.get('sink_count', 0)}")
        report.append(f"Execution Time: {stats.get('execution_time', 'N/A')}")
        report.append("")
        
        # Ïò§ÏóºÎêú Î≥ÄÏàò
        if self.analysis_result['tainted_variables']:
            report.append("TAINTED VARIABLES")
            report.append("-" * 40)
            for var in self.analysis_result['tainted_variables'][:20]:
                report.append(f"  ‚Ä¢ {var}")
            if len(self.analysis_result['tainted_variables']) > 20:
                report.append(f"  ... and {len(self.analysis_result['tainted_variables']) - 20} more")
            report.append("")
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏûëÏóÖ
        if self.analysis_result['database_sinks']:
            report.append("DATABASE OPERATIONS")
            report.append("-" * 40)
            for sink in self.analysis_result['database_sinks'][:10]:
                fields = ', '.join(sink['fields']) if sink['fields'] else 'ALL'
                report.append(f"  ‚Ä¢ {sink['operation']} {sink['table']} (Line {sink['line']})")
                report.append(f"    Fields: {fields}")
                report.append(f"    Source: {sink['source']}")
            report.append("")
        
        # Ï†ÑÌåå Í≤ΩÎ°ú
        if self.analysis_result['propagation_paths']:
            report.append("PROPAGATION PATHS")
            report.append("-" * 40)
            for path in self.analysis_result['propagation_paths'][:5]:
                report.append(f"  ‚Ä¢ {path['variable']}")
                report.append(f"    Path: {path['path']}")
                report.append(f"    Sink: {path['sink']}")
            report.append("")
        
        # Ï∂îÏ†Å Îã®Í≥Ñ
        if self.analysis_result['trace_steps']:
            report.append("TRACE STEPS")
            report.append("-" * 40)
            for step in self.analysis_result['trace_steps']:
                report.append(f"  {step}")
            report.append("")
        
        report_text = '\n'.join(report)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
        
        return report_text