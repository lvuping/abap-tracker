#!/usr/bin/env python3
"""
Test CSV ê¸°ë°˜ SY-UNAME ì¶”ì  ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ê¸°ëŠ¥:
- input/test.csv íŒŒì¼ì„ ì½ì–´ì„œ SY-UNAME ë¶„ì„ ì‹¤í–‰
- CSV í˜•ì‹: id, file_path, line_number
- ê²°ê³¼ë¥¼ output í´ë”ì— CSV ë° JSONìœ¼ë¡œ ì €ì¥

ì‚¬ìš©ë²•:
    python run_test_csv.py                    # ê¸°ë³¸ ì‹¤í–‰ (JSON + CSV)
    python run_test_csv.py --json-only       # JSONë§Œ ì¶œë ¥
    python run_test_csv.py --csv-only        # CSVë§Œ ì¶œë ¥
    python run_test_csv.py --verbose         # ìƒì„¸ ì¶œë ¥
"""

import csv
import json
import sys
import os
from datetime import datetime
from analyzer import trace_sy_uname_in_snippet
from encoding_utils import safe_file_read


def process_test_csv(input_file="input/test.csv", output_format="both", verbose=False):
    """
    test.csv íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ìƒì„±
    
    Args:
        input_file: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_format: "json", "csv", "both" ì¤‘ í•˜ë‚˜
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    all_results = []
    
    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if not os.path.exists(input_file):
        print(f"âŒ ì˜¤ë¥˜: {input_file} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ì…ë ¥ íŒŒì¼ì„ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ CSV íŒŒì¼ì„ ë§Œë“œì„¸ìš”:")
        print(f"   id,file_path,line_number")
        print(f"   1,test_basic,10")
        print(f"   2,user_example,5")
        return False
    
    print(f"ğŸ” Test CSV ê¸°ë°˜ SY-UNAME ì¶”ì  ë¶„ì„ ì‹œì‘")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_file}")
    print("=" * 80)
    
    # CSV íŒŒì¼ ì½ê¸° (ìë™ ì¸ì½”ë”© ê°ì§€)
    lines, encoding_used = safe_file_read(input_file)
    
    if verbose:
        print(f"ğŸ“ íŒŒì¼ ì¸ì½”ë”©: {encoding_used}")
    
    # CSV ë°ì´í„° ì²˜ë¦¬
    import io
    csv_content = io.StringIO(''.join(lines))
    reader = csv.DictReader(csv_content)
    
    # í—¤ë” í™•ì¸
    if not reader.fieldnames or not all(field in reader.fieldnames for field in ['id', 'file_path', 'line_number']):
        print(f"âŒ ì˜¤ë¥˜: CSV íŒŒì¼ì€ 'id', 'file_path', 'line_number' ì»¬ëŸ¼ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
        print(f"   í˜„ì¬ ì»¬ëŸ¼: {reader.fieldnames}")
        return False
    
    # ì´ í•­ëª© ìˆ˜ ê³„ì‚°
    rows = list(reader)
    total_items = len(rows)
    
    if total_items == 0:
        print(f"âš ï¸ ê²½ê³ : ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"ğŸ“Š ì´ {total_items}ê°œ í•­ëª© ë°œê²¬\n")
    
    # ê° í•­ëª© ì²˜ë¦¬
    for idx, row in enumerate(rows, 1):
        try:
            test_id = row['id'].strip()
            file_path = row['file_path'].strip()
            line_number = int(row['line_number'].strip())
            
            # .abap í™•ì¥ì ìë™ ì¶”ê°€
            if not file_path.endswith('.abap'):
                file_path = file_path + '.abap'
            
            # input/ ë””ë ‰í† ë¦¬ ê²½ë¡œ ìë™ ì¶”ê°€
            if not file_path.startswith('input/'):
                file_path = 'input/' + file_path
            
            print(f"ğŸ“ [{idx}/{total_items}] ID={test_id}: {os.path.basename(file_path)} (ë¼ì¸ {line_number})")
            
            # ABAP íŒŒì¼ ì½ê¸°
            if not os.path.exists(file_path):
                print(f"   âŒ íŒŒì¼ ì—†ìŒ: {file_path}")
                all_results.append({
                    'id': test_id,
                    'source_file': file_path,
                    'source_line': line_number,
                    'result': {
                        'status': 'File Not Found',
                        'error': f'File not found: {file_path}'
                    }
                })
                continue
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            all_lines, abap_encoding = safe_file_read(file_path)
            
            if verbose:
                print(f"   ğŸ“„ ABAP íŒŒì¼ ì¸ì½”ë”©: {abap_encoding}")
                print(f"   ğŸ“ íŒŒì¼ ì´ ë¼ì¸ ìˆ˜: {len(all_lines)}")
            
            # ë¶„ì„í•  ì½”ë“œ ë²”ìœ„ ì¶”ì¶œ (ì• 200ì¤„, ë’¤ 1000ì¤„)
            start = max(0, line_number - 201)
            end = min(len(all_lines), line_number + 1000)
            snippet = all_lines[start:end]
            
            # ìƒëŒ€ì  ë¼ì¸ ë²ˆí˜¸ ê³„ì‚°
            relative_start_line = line_number - start - 1
            
            # SY-UNAME ì¶”ì  ë¶„ì„ ì‹¤í–‰
            result = trace_sy_uname_in_snippet(snippet, relative_start_line)
            
            # ê²°ê³¼ ì¶œë ¥
            if result['status'] == 'Found':
                if result['type'] == 'RFC':
                    print(f"   âœ… RFC í˜¸ì¶œ ë°œê²¬: {result.get('name', 'Unknown')}")
                elif result['type'] == 'AUDIT_FIELD':
                    print(f"   âœ… ê°ì‚¬ í•„ë“œ: {result.get('structure')}-{result.get('field')}")
                elif result['type'] in ['DATABASE_UPDATE_FIELD', 'DATABASE_INSERT_FIELD', 
                                       'DATABASE_MODIFY_FIELD', 'DATABASE_SELECT_WHERE']:
                    fields = ', '.join(result.get('fields', []))
                    print(f"   ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤: {result.get('table')}.{fields} ({result.get('operation', 'UNKNOWN')})")
                elif result['type'].startswith('DATABASE_'):
                    print(f"   âœ… ë°ì´í„°ë² ì´ìŠ¤: {result.get('operation', 'UNKNOWN')} {result.get('table')}")
                else:
                    print(f"   âœ… Sink ë°œê²¬: {result['type']}")
                    
                if verbose and result.get('trace_path'):
                    print(f"   ğŸ“ ì¶”ì  ê²½ë¡œ ({len(result['trace_path'])}ë‹¨ê³„):")
                    for step in result['trace_path'][:5]:  # ì²˜ìŒ 5ë‹¨ê³„ë§Œ í‘œì‹œ
                        print(f"      â€¢ {step}")
                        
            elif result['status'] == 'Scope Boundary Reached':
                boundary_type = result.get('type', 'Unknown')
                print(f"   â›” ìŠ¤ì½”í”„ ê²½ê³„ ë„ë‹¬: {boundary_type}")
                if verbose:
                    print(f"      ë¼ì¸: {result.get('boundary_line', 'Unknown')}")
                    
            elif result.get('error_type') == 'SYUNAME_NOT_AT_SPECIFIED_LINE':
                print(f"   âŒ ì§€ì •ëœ ë¼ì¸ì— SY-UNAME ì—†ìŒ")
                if verbose:
                    print(f"      ì‹¤ì œ ë‚´ìš©: '{result.get('actual_content', 'N/A')}'")
                    
            elif result.get('error_type') == 'NO_SINK_FOUND_AFTER_TRACING':
                print(f"   âš ï¸ SY-UNAME ì¶”ì ë¨ but Sink ë¯¸ë°œê²¬")
                if verbose:
                    analysis = result.get('analysis_summary', {})
                    print(f"      ë¶„ì„ëœ ë¬¸ì¥: {analysis.get('total_statements_analyzed', 0)}ê°œ")
                    print(f"      ì¶”ì  ë‹¨ê³„: {analysis.get('trace_steps', 0)}ë‹¨ê³„")
            else:
                print(f"   âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {result.get('reason', 'Unknown')}")
            
            # ê²°ê³¼ ì €ì¥
            all_results.append({
                'id': test_id,
                'source_file': file_path,
                'source_line': line_number,
                'result': result
            })
            
        except Exception as e:
            print(f"   âŒ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            all_results.append({
                'id': row.get('id', 'Unknown'),
                'source_file': row.get('file_path', 'Unknown'),
                'source_line': row.get('line_number', 0),
                'result': {
                    'status': 'Error',
                    'error': str(e)
                }
            })
    
    # ê²°ê³¼ ì €ì¥
    print("\n" + "=" * 80)
    print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    output_dir = 'output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # JSON ì¶œë ¥
    if output_format in ['json', 'both']:
        json_file = f"{output_dir}/test_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ JSON ê²°ê³¼ ì €ì¥: {json_file}")
    
    # CSV ì¶œë ¥
    if output_format in ['csv', 'both']:
        csv_file = f"{output_dir}/test_results_{timestamp}.csv"
        export_to_csv(all_results, csv_file)
        print(f"ğŸ“Š CSV ê²°ê³¼ ì €ì¥: {csv_file}")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ‰ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ë¶„ì„ ìš”ì•½:")
    
    found_count = sum(1 for r in all_results if r['result'].get('status') == 'Found')
    boundary_count = sum(1 for r in all_results if r['result'].get('status') == 'Scope Boundary Reached')
    not_found_count = sum(1 for r in all_results if r['result'].get('error_type') == 'SYUNAME_NOT_AT_SPECIFIED_LINE')
    no_sink_count = sum(1 for r in all_results if r['result'].get('error_type') == 'NO_SINK_FOUND_AFTER_TRACING')
    error_count = sum(1 for r in all_results if r['result'].get('status') in ['Error', 'File Not Found'])
    
    print(f"  â€¢ ì´ ë¶„ì„: {len(all_results)}ê°œ")
    print(f"  â€¢ âœ… Sink ë°œê²¬: {found_count}ê°œ")
    print(f"  â€¢ â›” ìŠ¤ì½”í”„ ê²½ê³„: {boundary_count}ê°œ")
    print(f"  â€¢ âŒ SY-UNAME ì—†ìŒ: {not_found_count}ê°œ")
    print(f"  â€¢ âš ï¸ Sink ë¯¸ë°œê²¬: {no_sink_count}ê°œ")
    print(f"  â€¢ âŒ ì˜¤ë¥˜: {error_count}ê°œ")
    
    return True


def export_to_csv(results, output_file):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    if not results:
        return
    
    csv_rows = []
    max_trace_steps = 0
    
    for item in results:
        result = item['result']
        
        row = {
            'ID': item['id'],
            'Source_File': item['source_file'],
            'Line_Number': item['source_line'],
            'Status': result.get('status', 'Unknown'),
            'Type': result.get('type', ''),
            'Table': result.get('table', ''),
            'Fields': ', '.join(result.get('fields', [])) if result.get('fields') else '',
            'RFC_Name': result.get('name', '') if result.get('type') == 'RFC' else '',
            'Operation': result.get('operation', ''),
            'Description': result.get('description', ''),
            'Error': result.get('error', ''),
            'Trace_Steps': len(result.get('trace_path', result.get('path', [])))
        }
        
        # ì¶”ì  ê²½ë¡œ ì¶”ê°€ (ìµœëŒ€ 5ë‹¨ê³„)
        trace_path = result.get('trace_path', result.get('path', []))
        for i, step in enumerate(trace_path[:5], 1):
            row[f'Trace_Step_{i}'] = step
            max_trace_steps = max(max_trace_steps, i)
        
        csv_rows.append(row)
    
    # CSV íŒŒì¼ ì‘ì„±
    if csv_rows:
        # ê¸°ë³¸ í•„ë“œ ì´ë¦„ ì •ì˜
        fieldnames = [
            'ID', 'Source_File', 'Line_Number', 'Status', 'Type', 
            'Table', 'Fields', 'RFC_Name', 'Operation', 
            'Description', 'Error', 'Trace_Steps'
        ]
        
        # ì¶”ì  ë‹¨ê³„ í•„ë“œ ì¶”ê°€
        for i in range(1, max_trace_steps + 1):
            fieldnames.append(f'Trace_Step_{i}')
        
        with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            # ëª¨ë“  í•„ë“œê°€ ìˆë„ë¡ ë³´ì¥
            for row in csv_rows:
                complete_row = {field: row.get(field, '') for field in fieldnames}
                writer.writerow(complete_row)


def create_sample_test_csv():
    """
    ìƒ˜í”Œ test.csv íŒŒì¼ ìƒì„±
    """
    sample_file = 'input/test.csv'
    
    print(f"ğŸ“ ìƒ˜í”Œ test.csv íŒŒì¼ ìƒì„± ì¤‘...")
    
    sample_data = [
        ['id', 'file_path', 'line_number'],
        ['1', 'test_basic', '10'],
        ['2', 'user_example', '5'],
        ['3', '01_database_insert', '50'],
        ['4', '02_database_update', '45'],
        ['5', 'test_complex_flow', '25']
    ]
    
    with open(sample_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerows(sample_data)
    
    print(f"âœ… ìƒ˜í”Œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {sample_file}")
    print(f"   ì´ íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ì„¸ìš”.")
    return sample_file


def main():
    """
    ë©”ì¸ í•¨ìˆ˜
    """
    print("ğŸš€ Test CSV ê¸°ë°˜ SY-UNAME ì¶”ì ê¸°")
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    output_format = 'both'  # ê¸°ë³¸ê°’
    verbose = False
    create_sample = False
    
    if '--json-only' in sys.argv:
        output_format = 'json'
    elif '--csv-only' in sys.argv:
        output_format = 'csv'
    
    if '--verbose' in sys.argv or '-v' in sys.argv:
        verbose = True
    
    if '--create-sample' in sys.argv:
        create_sample = True
    
    # ìƒ˜í”Œ íŒŒì¼ ìƒì„± ì˜µì…˜
    if create_sample:
        create_sample_test_csv()
        return 0
    
    # test.csv íŒŒì¼ í™•ì¸
    test_file = 'input/test.csv'
    if not os.path.exists(test_file):
        print(f"âš ï¸ {test_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ìƒ˜í”Œ íŒŒì¼ì„ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print(f"   python {sys.argv[0]} --create-sample")
        return 1
    
    # ë¶„ì„ ì‹¤í–‰
    success = process_test_csv(test_file, output_format, verbose)
    
    if not success:
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())